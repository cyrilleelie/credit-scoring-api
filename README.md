---
title: Credit Scoring API
emoji: ğŸ¤–
colorFrom: green
colorTo: blue
sdk: docker
app_port: 8000
pinned: false
---

# API de Scoring CrÃ©dit & Dashboard de Monitoring

[![Licence: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

Ce projet a pour objectif de dÃ©ployer un modÃ¨le de Machine Learning de scoring crÃ©dit via une API robuste (FastAPI) et de fournir un dashboard interactif (Streamlit) pour l'analyse et le monitoring en temps rÃ©el. L'ensemble de l'application est conÃ§u pour Ãªtre conteneurisable avec Docker et est supportÃ© par une base de donnÃ©es PostgreSQL.

### ğŸš€ AccÃ¨s Ã  l'API DÃ©ployÃ©e

* **API & Documentation (Hugging Face) :** [API sur Hugging Face Spaces](https://cyrille-elie-credit-scoring-dashboard.hf.space/docs)

---

## ğŸ›ï¸ Architecture

L'application est composÃ©e de trois services principaux conÃ§us pour fonctionner ensemble :

1.  **Base de DonnÃ©es PostgreSQL** : ConteneurisÃ©e avec Docker pour le dÃ©veloppement local et hÃ©bergÃ©e sur une base de donnÃ©es SQL Cloud (Google) pour la production.
2.  **API FastAPI** : Sert le modÃ¨le de scoring. Elle expose des endpoints sÃ©curisÃ©s pour l'authentification et la prÃ©diction, et enregistre chaque appel dans la base de donnÃ©es de production.
3.  **Dashboard Streamlit (Local)** : Fournit une interface utilisateur pour interagir avec l'API dÃ©ployÃ©e, visualiser les performances et analyser la dÃ©rive des donnÃ©es. **Ce dashboard est conÃ§u pour Ãªtre lancÃ© localement.**

## ğŸ“‚ Structure du Projet

Le code est organisÃ© en modules fonctionnels pour une meilleure clartÃ© et maintenabilitÃ©.

```
credit-scoring-api/
â”œâ”€â”€ .github/workflows/    # Workflows d'IntÃ©gration Continue (CI)
â”œâ”€â”€ model_artifacts/      # ModÃ¨les entraÃ®nÃ©s (ignorÃ© par Git)
â”œâ”€â”€ src/                  # Code source de l'application
â”‚   â”œâ”€â”€ api/              # Logique de l'API FastAPI
â”‚   â”œâ”€â”€ config/           # Configuration de l'application
â”‚   â”œâ”€â”€ dashboard/        # Logique du Dashboard Streamlit
â”‚   â”‚   â””â”€â”€ app_dashboard.py
â”‚   â”œâ”€â”€ database/         # ModÃ¨les de donnÃ©es et connexion BDD
â”‚   â””â”€â”€ scripts/          # Scripts utilitaires (init_db, profiling, etc.)
â”œâ”€â”€ tests/                # Tests automatisÃ©s
â”‚   â”œâ”€â”€ fixtures/         # Petits jeux de donnÃ©es pour les tests
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ .env.example          # Fichier d'exemple pour la configuration
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml    # Configuration pour lancer la BDD avec Docker
â””â”€â”€ pyproject.toml        # DÃ©pendances et configuration du projet (Poetry)
```

## ğŸš€ Installation et Lancement Local

Suivez ces Ã©tapes pour lancer l'application en environnement de dÃ©veloppement.

### 1. PrÃ©requis

* [Git](https://git-scm.com/)
* [Python 3.12+](https://www.python.org/)
* [Poetry](https://python-poetry.org/)
* [Docker](https://www.docker.com/) et Docker Compose

### 2. Cloner le DÃ©pÃ´t

```bash
git clone https://github.com/cyrilleelie/credit-scoring-api
cd credit-scoring-api
```

### 3. Fichier de Configuration

CrÃ©ez votre fichier de configuration local Ã  partir de l'exemple fourni.

```bash
cp .env.example .env
```

**Action requise :** Ouvrez le fichier `.env` et remplissez les valeurs.

* Pour un **test purement local**, utilisez les identifiants de la base de donnÃ©es Docker.
* Pour connecter le **dashboard local Ã  l'API de production**, remplissez les variables avec les identifiants de votre base de donnÃ©es Cloud.

### 4. Installer les DÃ©pendances

```bash
poetry install
```

### 5. DÃ©marrer la Base de DonnÃ©es (pour test local)

Lancez le conteneur PostgreSQL en arriÃ¨re-plan avec Docker Compose :

```bash
docker-compose up -d
```

### 6. Initialiser la Base de DonnÃ©es (pour test local)

Ce script crÃ©e le schÃ©ma de la base de donnÃ©es et y charge les donnÃ©es des clients.

```bash
poetry run python -m src.scripts.init_db
```

### 7. Lancer l'API FastAPI (pour test local)

Dans un premier terminal :

```bash
poetry run uvicorn src.api.main:app --reload
```

L'API sera accessible Ã  l'adresse `http://127.0.0.1:8000`.

### 8. Lancer le Dashboard Streamlit

Dans un second terminal :

```bash
poetry run streamlit run src/dashboard/app_dashboard.py
```

Le dashboard sera accessible Ã  l'adresse `http://localhost:8501`. Il se connectera Ã  l'API et Ã  la base de donnÃ©es configurÃ©es dans votre fichier `.env`.

## âœ… Tests

Pour lancer la suite de tests automatisÃ©s, exÃ©cutez la commande suivante depuis la racine du projet :

```bash
poetry run pytest
```

## ğŸ”¬ Analyse de Performance

Cette section dÃ©crit les outils utilisÃ©s pour mesurer et analyser la performance de l'API. **Assurez-vous que le serveur de l'API est en cours d'exÃ©cution** avant de lancer ces scripts.

### Profiling de l'API (`cProfile`)

```bash
poetry run python -m src.scripts.profile_api
```

### Test de Charge (`Locust`)

1.  **Lancez Locust :**
    ```bash
    poetry run locust -f src/scripts/locustfile.py --host="http://127.0.0.1:8000"
    ```
2.  **Ouvrez l'interface web de Locust** dans votre navigateur Ã  l'adresse `http://localhost:8089`.
3.  **Configurez et dÃ©marrez un test** en spÃ©cifiant le nombre d'utilisateurs et le taux d'apparition.

---

### âš–ï¸ ConformitÃ© RGPD et Ã‰thique

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans le respect de la confidentialitÃ© des donnÃ©es.

* **Anonymisation** : Les donnÃ©es utilisÃ©es pour l'entraÃ®nement et les prÃ©dictions sont anonymisÃ©es. L'identifiant client est le seul moyen de relier une prÃ©diction Ã  une entitÃ©.
* **Transparence du ModÃ¨le** : Le dashboard permet de monitorer la dÃ©rive des donnÃ©es, assurant ainsi une surveillance continue du comportement du modÃ¨le pour dÃ©tecter d'Ã©ventuels biais ou une dÃ©gradation de sa pertinence.
* **Droit Ã  l'Oubli** : Bien que non implÃ©mentÃ©e, l'architecture permettrait d'ajouter une fonctionnalitÃ© pour supprimer les donnÃ©es d'un client de la base de donnÃ©es sur demande.
